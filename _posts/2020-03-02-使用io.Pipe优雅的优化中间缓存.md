## 使用io.Pipe优雅的优化中间缓存

#### BEFORE

近期实现了一个HTTP中转文件上传/下载请求到指定存储引擎的proxy服务，主要用于过滤非法访问。期间踩了一些坑，这里分享一下，有助于理解go的I/O实现。

刚上线的文件存储proxy，发现内存占用很大，代码如下：

```go
func upload(g *gin.context){
  // 获取多文件表单reader
	multipartReader, _ := g.Request.MultipartReader()
  // 获取表单中的第一个part
	part, _ := multipartReader.NextPart()
	filename := part.FileName()
	body := &bytes.Buffer{}
	writer := multipart.NewWriter(body)
  defer writer.Close()
	h := make(textproto.MIMEHeader)
	h.Set("Content-Type", mime.TypeByExtension(strings.ToLower(filepath.Ext(fileName))))
  // 基于文件header创建一个part
	desPart, err := writer.CreatePart(h)
	if err != nil {
		return
	}
  // 拷贝文件新的part中，新的part最终写入在bytes.buffer
	io.Copy(desPart, part)
	http.post(ctx, remotepath, body)

}
```

尝试上传一个2.8G的文件中，pprof中可以看到`makeSlice`占用了大量内存

```
(pprof) top
Showing nodes accounting for 2.88GB, 99.79% of 2.88GB total
Dropped 42 nodes (cum <= 0.01GB)
Showing top 10 nodes out of 16
      flat  flat%   sum%        cum   cum%
    2.88GB 99.79% 99.79%     2.88GB 99.79%  bytes.makeSlice
```

在服务间发送json数据时，经常通过声明一个`bytes`缓存，然后通过`json`把结构体中的内容mashal成字节流，再通过Post请求发送。

`bytes.Buffer`完全基于内存读写，在传递一些消息时非常方便，但是在文件传输场景下，很容易就把内存吃满。

## 解决方案

### 1. request.FormFile

写临时文件缓存，request包中提供了`FormFile`方法，该方法占用固定大小的内存，将表单文件读入内存/硬盘

```
	func upload(g *gin.context){
		f,fHeader, err := c.Request.FormFile("file")
		http.post(ctx, remotepath, f)
	}
```

实际使用中占用了固定大小的内存空间，默认为30MB,不足30MB的文件直接写bytes.Buffer，也就是驻留在内存中，>30MB的文件则写入系统临时文件。

主要实现如下：

```go
func (r *Reader) readForm(maxMemory int64) (_ *Form, err error) {
	form := &Form{make(map[string][]string), make(map[string][]*FileHeader)}
  // 额外分配空间给 non-file parts
	maxValueBytes := maxMemory + int64(10<<20)
	for {
    // 读取一个part
		p, err := r.NextPart()
		if err == io.EOF {
			break
		}
		filename := p.FileName()
		var b bytes.Buffer
		fh := &FileHeader{
			Filename: filename,
			Header:   p.Header,
		}
    // 拷贝到bytes.buffer,这里指定了最大长度
		n, err := io.CopyN(&b, p, maxMemory+1)
		if err != nil && err != io.EOF {
			return nil, err
		}
		if n > maxMemory {
      // 文件 > maxMemory，写临时文件
			file, err := os.CreateTemp("", "multipart-")
			if err != nil {
				return nil, err
			}
			size, err := io.Copy(file, io.MultiReader(&b, p))
			if cerr := file.Close(); err == nil {
				err = cerr
			}
			if err != nil {
				os.Remove(file.Name())
				return nil, err
			}
			fh.tmpfile = file.Name()
			fh.Size = size
		} else {
      // 文件 < maxMemory，留在内存中(bytes.Buffer)
			fh.content = b.Bytes()
			fh.Size = int64(len(fh.content))
			maxMemory -= n
			maxValueBytes -= n
		}
		form.File[name] = append(form.File[name], fh)
	}
	return form, nil
}
```

### 2. io.pipe

方案1已经可以解决内存占用过大的问题了，但大文件需要等待完全复制到磁盘才可提交post请求，有没有更优雅的方式呢？

io包的pipe函数返回一个reader和一个writer,通过writer写入的数据可以通过reader读取处理。

```
func Pipe() (*PipeReader, *PipeWriter)
```

**口语化的方式来讲一下它们是如何工作的** [引用自https://www.jianshu.com/p/aa207155ca7d]

> 假设我们在工地上，有两个工人，一个叫w，一个叫r，w负责搬砖，而r负责砌墙。
>
> 初始。 w深知r懒惰的习性，当它把砖搬过来后，就把r叫醒(`Signal`)。然后w心想，反正你砌墙也要一会儿，那我也睡会儿。于是w叫醒r后它也开始睡觉(`Wait`)。
>
> 砖来了。w深知r懒惰的习性，当它把砖搬过来后，就把r叫醒(`Signal`)。然后w心想，反正你砌墙也要一会儿，那我也睡会儿。于是w叫醒r后它也开始睡觉(`Wait`)。
>
> 砌墙。 r被叫醒之后，心想着睡了这么久害怕被包工头责骂，自然就开始辛勤地砌墙了，很快就把w搬过来的砖用完了。r心想，这墙砌不完可怪不到我头上，因为没砖了，于是r叫醒了w，然后自己又去睡觉了。
>
> 继续搬砖。w被叫醒后一看，哎哟我去，这么快就没砖了？然后他又跑去搬了些转过来，然后叫醒睡得跟死猪一样的r起来砌墙，自己又开始睡觉……
>
> 周而复始。 直到……w和r两人就这么周而复始地配合，直到r发现墙砌好了，或者w发现工地上已经没有砖了。

##### 使用实例：

```go
func main() {
	r, w := io.Pipe()
	// reader和writer必须在不同的goroutine中执行否则会造成死锁
	go func() {
		w.Write([]byte("hello word"))
		w.Close()
	}()
	buffer := make([]byte, 20)
	r.Read(buffer)
	fmt.Println(string(buffer))
}

exec:
hello word
```

引入到我们的上传方法中,通过pipe创建的reader,writer以及两个goroutine可以实时收发,且不需要任何中间缓存。

```go
func upload(g *gin.context){
	multipartReader, _ := g.Request.MultipartReader()
  // 获取文件part
	part, _ := multipartReader.NextPart()
  r, w := io.Pipe()
  // 基于pipe的writer创建一个multipartWriter
  mw := multipart.NewWriter(w)
  go func() {
    h := make(textproto.MIMEHeader)
		h.Set("Content-Type", mime.TypeByExtension(strings.ToLower(filepath.Ext(fileName))))
    // 基于multipartWriter创建一个part
		desPart, _ := mw.CreatePart(h)
    // 文件part拷贝到新创建的despart中，despart由multipartWrite创建，最终数据写入了pipe的Writer中
    fileSize, _ := io.Copy(desPart, part)
    mw.Close()
		w.Close()
	}()
  // 发送post请求，body为pipe的Reader
  resp, _ :=http.post(ctx, remotepath, r)
  ...
}
```

使用中，可以使用一些workpool来专门处理这些io任务，避免goroutine频繁创建(不加也没关系，反正都很轻)

#### 那么pipe时如何实现的呢？

先来看一下pipe的结构

```go
type pipe struct {
	wrMu sync.Mutex   // 禁止并发写
	wrCh chan []byte  // 无缓冲的chan传递数据
	rdCh chan int     // 无缓冲的chan传递数据的字节数

	once sync.Once    // 保证done chan只close一次
	done chan struct{} // 通过done chan通信告知传递结束，注意【struct零值就是本身，读取close的channel返回零值】
	rerr onceError
	werr onceError
}
```

```go
// 从pipe中读取数据
func (p *pipe) Read(b []byte) (n int, err error) {
	select {
	case <-p.done:
    // pipe close
		return 0, p.readCloseError()
	default:
	}

	select {
  // 通过wrCh读取数据，write goroutine在此阻塞，直到读取完成将被唤醒
	case bw := <-p.wrCh:
    // 拷贝数据到指定的输出
		nr := copy(b, bw)
    // 向write发送本次读取的字节数
		p.rdCh <- nr
		return nr, nil
	case <-p.done:
    // pipe close
		return 0, p.readCloseError()
	}
}
```

```go
// 向pipe中写数据
func (p *pipe) Write(b []byte) (n int, err error) {
	select {
	case <-p.done:
    // pipe close
		return 0, p.writeCloseError()
	default:
		p.wrMu.Lock()
		defer p.wrMu.Unlock()
	}
	// once保证至少执行一次
	for once := true; once || len(b) > 0; once = false {
		select {
    //将数据写入无缓冲的chan，如果之前的数据没有读出去将继续阻塞
		case p.wrCh <- b:
      // 等待读的goroutine返回读取的字节数
			nw := <-p.rdCh
      // 一次未写完，记录偏移
			b = b[nw:]
			n += nw
		case <-p.done:
      // 如果pipe关闭，返回写入的字节数
			return n, p.writeCloseError()
		}
	}
	return n, nil
}
```

pipe内部通过两个无缓冲的chan巧妙的实现同步内存管道，简单又强大。

## 总结

可以看出go的优势不仅仅是支持了轻量级线程(goroutine)，其中的一些I/O操作的实现也是非常优雅。

使用pipe，可以非常方便的链接不同输入输出的数据流，有了它，我们终于可以甩去臃肿的中间缓存了～～
